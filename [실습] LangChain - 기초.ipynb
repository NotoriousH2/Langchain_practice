{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a435919b",
   "metadata": {},
   "source": [
    "# [실습] LangChain 활용\n",
    "\n",
    "\n",
    "지난 시간에 사용했던 OpenAI API는 OpenAI의 기본적인 모든 기능들을 사용하게 해 주는 역할을 했습니다.   \n",
    "프롬프트를 작성하고, 파일을 전송하거나 이미지를 생성하는 실습을 같이 해 봤는데요.    \n",
    "실제 LLM을 활용한 어플리케이션을 만들 때에는 단순히 기능을 활용하는 것 이외에 다른 요소가 추가될 수 있습니다.\n",
    "\n",
    "오늘은 LLM 어플리케이션을 쉽게 개발할 수 있게 해주는 라이브러리인 LangChain(랭체인)을 배워 보겠습니다.   \n",
    "랭체인의 공식 홈페이지는 https://python.langchain.com/docs/get_started/introduction 입니다.   \n",
    "\n",
    "\n",
    "---\n",
    "LangChain은 [https://integrations.langchain.com/llms] 다양한 LLM 모델과 연동됩니다.   \n",
    "여기서는 OpenAI의 LLM 모델을 사용합니다.\n",
    "\n",
    "LangChain 기능을 활용하기 위해서는 OpenAI API 키가 필요합니다.   \n",
    "[여기](https://platform.openai.com/account/api-keys)를 클릭하여 키를 생성할 수 있습니다.   \n",
    "\n",
    "OpenAI의 API를 연동하여 사용하므로, LangChain 역시 기본적으로 유료이며, API 사용 시마다 토큰(token)을 지불해야 합니다.    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf68e6c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.335)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.0.64)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.0.20)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\13lue\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install cohere openai cohere tiktoken faiss-gpu langchain\n",
    "\n",
    "# langchain 최신버전 : 0.0.335 설치 (아주 초창기임을 알 수 있죠...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d43bb6",
   "metadata": {},
   "source": [
    "LangChain의 기능을 하나하나 import하며, 실습을 진행해 보겠습니다.   \n",
    "우선 환경 변수를 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13da3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부여받은 api key를 여기에 복사합니다.\n",
    "import os\n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"<OpenAI_API의 API 키>\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# 다른 방법 : OpenAI에 키 집어넣어서 생성하기\n",
    "#from langchain.llms import OpenAI\n",
    "#llm = OpenAI(openai_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b03d9",
   "metadata": {},
   "source": [
    "LangChain의 주요 모듈은 아래와 같습니다.   \n",
    "- LLM: LLM 호출을 위한 인터페이스\n",
    "- Prompt: 프롬프트 템플릿을 구성\n",
    "- Chain: 프롬프트의 입출력과 LLM을 연결하는 모듈\n",
    "- Agent: 사용자의 요청에 따라 여러 기능을 순차적으로 실행\n",
    "- Tools: 에이전트에서 수행할 특정 기능\n",
    "- Memory: 어플리케이션의 메모리(기억) 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4252b",
   "metadata": {},
   "source": [
    "## 1. LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e2ffb7",
   "metadata": {},
   "source": [
    "OpenAI의 LLM인 ChatGPT를 불러오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996f34e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23723634",
   "metadata": {},
   "source": [
    "OpenAI()의 기본 설정은 아래와 같습니다.\n",
    "- model= 'text-davinci-003', temperature = 0.7, max_tokens = 256, top_p = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0648c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20442d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"I\\'ll be back\"  - 커터 스카우트 (터미네이터 시리즈)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"전 세계적으로 흥행한 영화에 나오는 유명한 명대사를 하나 알려주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b0c4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1573c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "442b54b8",
   "metadata": {},
   "source": [
    "## 2. Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050a9165",
   "metadata": {},
   "source": [
    "LLM 어플리케이션의 프롬프트는 사용자 입력을 가공하여 만들어지고, 전달됩니다.   \n",
    "LangChain에는 이를 조금 쉽게 수행하는 기능이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b72019",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt 템플릿 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2585b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5fbba7",
   "metadata": {},
   "source": [
    "PromptTemplate을 이용하여, 프롬프트의 기본적인 형태를 만들 수 있습니다.   \n",
    "`hello_template`에, 사용자의 이름을 넣어 인사하는 프롬프트 템플릿을 작성해 봅시다.    \n",
    "**username**이라는 필드를 중괄호로 묶어 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22354ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕, 나는 {username}야. 잘 부탁해.\n",
      "\n",
      "안녕, 나는 HH야. 잘 부탁해.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hello_template = \"안녕, 나는 {username}야. 잘 부탁해.\\n\"\n",
    "print(hello_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c41c93",
   "metadata": {},
   "source": [
    "파이썬 기본 라이브러리에서는 문자열 뒤에 .format()을 붙이고 각 필드의 정보를 입력하면 포함되는 기능이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5544c22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕, 나는 HH야. 잘 부탁해.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hello_template.format(username='HH'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c6515",
   "metadata": {},
   "source": [
    "Langchain도 비슷한 방식으로 작동합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7ef1d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕, 나는 HH야. 잘 부탁해.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello_prompt = PromptTemplate(input_variables = [\"username\"],\n",
    "                       template = hello_template)\n",
    "\n",
    "hello_prompt.format(username = \"HH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd5f2ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57a650ca",
   "metadata": {},
   "source": [
    "두 개의 매개변수를 받아 프롬프트를 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a2bc2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'피라미드에 대해 일본어로 설명하세요.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_template = \"{topic}에 대해 {language}로 설명하세요.\"\n",
    "\n",
    "translate_prompt = PromptTemplate(input_variables = [\"topic\",\"language\"],\n",
    "                            template = translate_template)\n",
    "translate_template.format(topic='피라미드', language='일본어')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756b8c2",
   "metadata": {},
   "source": [
    "## 3. Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc71ba29",
   "metadata": {},
   "source": [
    "앞에서 만든 프롬프트 템플릿과 llm을 묶어서 사용하기 위해 체인 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63c5bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a5d38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm \n",
    "llm = OpenAI(temperature=0.9)\n",
    "# prompt\n",
    "translate_template = \"{topic}에 대해 {language}로 설명하세요.\"\n",
    "translate_prompt = PromptTemplate(input_variables = [\"topic\",\"language\"],\n",
    "                            template = translate_template)\n",
    "\n",
    "#chain\n",
    "\n",
    "translate_chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = translate_prompt\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26d1be34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nピラミッドとは、四角形の基礎となる平面の上に、上向きの四角形の底面を持つ三角形を順に重ねた建造物です。古代エジプトでは、神秘的な力を持つとされ、今でも、観光地として見ることができます。'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_chain.run({'topic': \"피라미드\",'language':\"일본어\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991d933",
   "metadata": {},
   "source": [
    "## 4. Agent & Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92fe7e",
   "metadata": {},
   "source": [
    "에이전트는 사용자의 요청에 따라 순차적으로 입력할 프롬프트를 생성하고, 이를 바탕으로 결과를 도출하는 모듈입니다.   \n",
    "에이전트는 llm 모델과 함께 사용할 도구(Tool)을 넣어주게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcef4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import load_tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904aab63",
   "metadata": {},
   "source": [
    "수학에 특화된 llm-math 에이전트를 불러오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f4b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(\n",
    "    tool_names = [\"llm-math\"],\n",
    "    llm = OpenAI(temperature=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cad5285",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_agent= initialize_agent(\n",
    "    agent=\"zero-shot-react-description\", # 에이전트 타입 설정\n",
    "    llm= OpenAI(temperature=0.1),\n",
    "    tools = tools,\n",
    "    verbose=True # 작동 과정 출력\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ded454e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use a calculator to solve this equation.\n",
      "Action: Calculator\n",
      "Action Input: 3.5*4+3\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 17.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: 17.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'17.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_agent.run(\"3.5*4+3 의 값을 계산하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e693dda",
   "metadata": {},
   "source": [
    "Agent의 반응을 보면, 계산기 도구를 사용하여 문제를 푸는 과정이 나와 있는데요.   \n",
    "단순 계산기뿐만 아니라 구글 검색 API 도구 등을 활용하면 이를 스스로 판단하여 사용하기도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e2973",
   "metadata": {},
   "source": [
    "## 5. Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656cb81",
   "metadata": {},
   "source": [
    "대화의 히스토리를 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d2553ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82ae21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm = OpenAI(temperature=0.1),\n",
    "    verbose= True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da113fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 내일은 기말고사 시험일입니다.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 내일은 기말고사 시험일이군요. 나는 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"내일은 기말고사 시험일입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aaa622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 내일은 기말고사 시험일입니다.\n",
      "AI:  내일은 기말고사 시험일이군요. 나는 어떻게 도와드릴까요?\n",
      "Human: 나는 오늘 무엇을 해야 할까요?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 오늘은 기말고사 준비를 하는 것이 좋을 것 같습니다. 문제를 풀고, 중요한 개념을 다시 한 번 읽어보는 것도 좋을 것 같습니다.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"나는 오늘 무엇을 해야 할까요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dd59320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51eef87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='안녕, ChatGPT!', additional_kwargs={}, example=False), AIMessage(content='안녕하세요! 어떻게 도와드릴까요?', additional_kwargs={}, example=False)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"안녕, ChatGPT!\")\n",
    "history.add_ai_message(\"안녕하세요! 어떻게 도와드릴까요?\")\n",
    "\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f283255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "add97b81",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35db087",
   "metadata": {},
   "source": [
    "여러 LLM 결과를 연결할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429415b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f004cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20b12562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m챗봇은 인공지능 기술을 활용하여 대화하는 컴퓨터 프로그램입니다. 일반적으로 챗봇은 채팅 인터페이스를 통해 사용자와 대화하며, 자연어 처리 기술을 사용하여 사용자의 질문이나 요청을 이해하고 응답합니다.\n",
      "\n",
      "챗봇은 다양한 용도로 활용될 수 있습니다. 예를 들어, 고객 서비스를 자동화하기 위해 사용자의 문의나 요청에 대한 답변을 제공할 수 있습니다. 또는 여행 예약, 음식 주문, 날씨 정보 등과 같은 일상적인 작업을 처리하는데 사용될 수도 있습니다.\n",
      "\n",
      "챗봇은 일반적으로 사전에 학습된 데이터나 규칙을 기반으로 작동합니다. 예를 들어, 자주 묻는 질문에 대한 미리 정의된 답변을 제공하거나, 사용자의 입력을 분석하여 해당하는 응답을 선택하는 방식으로 동작할 수 있습니다. 또는 기계 학습 기술을 사용하여 대화 데이터를 학습하고, 실시간으로 새로운 상황에 대응하는 방식으로도 동작할 수 있습니다.\n",
      "\n",
      "챗봇은 사용자 경험을 향상시키기 위해 계속해서 발전하고 있습니다. 최신 기술을 활용하여 자연스러운 대화, 개인화된 응답, 문맥 파악 등을 구현하여 사용자와의 상호작용을 더욱 원활하고 효과적으로 만들어낼 수 있습니다.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m- \"인공지능 기술\"은 어떤 종류의 기술을 포함하나요?\n",
      "- \"자연어 처리 기술\"은 어떤 방식으로 동작하나요?\n",
      "- \"챗봇\"과 \"대화 인터페이스\"의 차이점은 무엇인가요?\n",
      "- \"고객 서비스 자동화\"는 어떤 식으로 이루어지나요?\n",
      "- \"사전에 학습된 데이터\"와 \"규칙\"을 기반으로 작동하는 챗봇의 차이점은 무엇인가요?\n",
      "- \"기계 학습\"을 사용하는 챗봇은 어떻게 작동하나요?\n",
      "- \"최신 기술\"을 활용한 챗봇은 어떤 기능을 제공하나요?\n",
      "- \"자연스러운 대화\"를 구현하기 위해 어떤 기술이 사용되나요?\n",
      "- \"개인화된 응답\"을 구현하기 위해 어떤 정보가 필요한가요?\n",
      "- \"문맥 파악\"을 위해 어떤 방식이 사용되나요?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7, openai_api_key='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')\n",
    "\n",
    "template_long = \"당신은 유능한 AI 비서입니다. {topic}에 대해 설명하세요.\"\n",
    "prompt_long = PromptTemplate(input_variables=[\"topic\"],\n",
    "                            template=template_long)\n",
    "\n",
    "template_long2 = \"당신은 중학생입니다. {explanation}을 읽고 이해하기 어려운 표현들과 예상 질문을 나열해 주세요.\"\n",
    "prompt_long2  = PromptTemplate(input_variables=['explanation'],template=template_long2)\n",
    "\n",
    "\"\"\"template = '다음을 그대로 따라해\\n안녕, {target}!'\n",
    "prompt_template = PromptTemplate(\n",
    "input_variables=[\"target\"],\n",
    "template=template)\"\"\"\n",
    "\n",
    "chain_1 = LLMChain(llm=llm, prompt=prompt_long)\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt_long2)\n",
    "\n",
    "chains = SimpleSequentialChain(\n",
    "        chains = [chain_1, chain_2],\n",
    "        verbose= True\n",
    ")\n",
    "\n",
    "review = chains.run('챗봇')\n",
    "\n",
    "#chains.run(role='유능한 AI 비서', topic='LangChain', reference='위키피디아')\n",
    "\n",
    "#prompt_long.format(role='유능한 AI 비서', topic='LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc5aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "089a7245",
   "metadata": {},
   "source": [
    "프롬프트 생성 주요 옵션\n",
    "\n",
    "- Temperature\n",
    "- Top P, Top K\n",
    "- Maximum Length\n",
    "- Frequency penalty\n",
    "- Presency penalty\n",
    "- Stop sequence\n",
    "- Injection Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c520cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddb28fa3",
   "metadata": {},
   "source": [
    "## <참고> 스트리밍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "180ca2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d76f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "톨킨의 제왕이라 불리는 나는 이름이 그리스도라고 합니다. 나는 오랜 시간 동안 인간들을 위해 사랑과 용기를 전해왔습니다. 나는 인간들이 자신의 삶을 즐기고 자신의 운명을 찾을 수 있도록 도와주고 싶습니다. 나는 인간들이"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n톨킨의 제왕이라 불리는 나는 이름이 그리스도라고 합니다. 나는 오랜 시간 동안 인간들을 위해 사랑과 용기를 전해왔습니다. 나는 인간들이 자신의 삶을 즐기고 자신의 운명을 찾을 수 있도록 도와주고 싶습니다. 나는 인간들이'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(\n",
    "    streaming=True,\n",
    "    callbacks = [StreamingStdOutCallbackHandler()],\n",
    "    verbose= True,\n",
    "    temperature=0.1\n",
    ")\n",
    "llm(\"반지의 제왕의 J.R.R 톨킨 스타일로 당신의 소개를 해 보세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26797d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba8cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab759b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8cf383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b482b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a361f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
